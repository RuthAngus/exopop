\documentclass[12pt,preprint]{aastex}

\usepackage{color,hyperref}
\definecolor{linkcolor}{rgb}{0,0,0.5}
\hypersetup{colorlinks=true,linkcolor=linkcolor,citecolor=linkcolor,
            filecolor=linkcolor,urlcolor=linkcolor}
\usepackage{url}
\usepackage{amssymb,amsmath}

\newcommand{\project}[1]{{\sffamily #1}}
\newcommand{\emcee}{\project{emcee}}
\newcommand{\kepler}{\project{Kepler}}
\newcommand{\license}{MIT License}

\newcommand{\paper}{\emph{Article}}

\newcommand{\foreign}[1]{\emph{#1}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}

\newcommand{\Fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\fig}[1]{\Fig{#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\Tab}[1]{Table~\ref{tab:#1}}
\newcommand{\tab}[1]{\Tab{#1}}
\newcommand{\tablabel}[1]{\label{tab:#1}}
\newcommand{\Eq}[1]{Equation~(\ref{eq:#1})}
\newcommand{\eq}[1]{\Eq{#1}}
\newcommand{\eqlabel}[1]{\label{eq:#1}}
\newcommand{\Sect}[1]{Section~\ref{sect:#1}}
\newcommand{\sect}[1]{\Sect{#1}}
\newcommand{\App}[1]{Appendix~\ref{sect:#1}}
\newcommand{\app}[1]{\App{#1}}
\newcommand{\sectlabel}[1]{\label{sect:#1}}

\newcommand{\dd}{\ensuremath{\,\mathrm{d}}}
\newcommand{\bvec}[1]{\ensuremath{\boldsymbol{#1}}}
\newcommand{\appropto}{\mathrel{\vcenter{
  \offinterlineskip\halign{\hfil$##$\cr
    \propto\cr\noalign{\kern2pt}\sim\cr\noalign{\kern-2pt}}}}}

% TO DOS
\newcommand{\todo}[3]{{\color{#2} \emph{#1} TODO: #3}}
\newcommand{\dfmtodo}[1]{\todo{DFM}{red}{#1}}
\newcommand{\hoggtodo}[1]{\todo{HOGG}{blue}{#1}}
\newcommand{\mortontodo}[1]{\todo{MORTON}{green}{#1}}

% Document specific variables.
\newcommand{\rate}{\ensuremath{\eta}}
\newcommand{\ratepars}{{\ensuremath{\bvec{\theta}}}}
\newcommand{\obs}[1]{\ensuremath{\hat{#1}}}
\newcommand{\radius}{\ensuremath{R}}
\newcommand{\period}{\ensuremath{T}}
\newcommand{\completeness}{{\ensuremath{P_\mathrm{c}}}}
\newcommand{\transitprob}{{\ensuremath{P_\mathrm{t}}}}
\newcommand{\entry}{\ensuremath{S}}
\newcommand{\catalog}{{\ensuremath{\bvec{\entry}}}}

\newcommand{\interim}{{\ensuremath{\bvec{\alpha}}}}

%
%  RULES OF THE GAME, MOTHAFUCKERS.
%
%  * 80 characters
%  * line breaks at the ends of sentences
%  * eqnarrys ONLY
%  * ALWAYS cite inside parens () and use \citealt{}; no in-line cites
%  * that is all.
%

\begin{document}

\title{%
  Inferring the distribution and rate of Earth-like exoplanets \\
  from noisy individual-planet inferences
}

\newcommand{\nyu}{2}
\newcommand{\mpia}{3}
\newcommand{\princeton}{4}
\newcommand{\berkeley}{5}
\author{%
    Daniel~Foreman-Mackey\altaffilmark{1,\nyu},
    David~W.~Hogg\altaffilmark{\nyu,\mpia},
    Timothy~D.~Morton\altaffilmark{\princeton},
    Erik~A.~Petigura\altaffilmark{\berkeley},
    \etal
}
\altaffiltext{1}         {To whom correspondence should be addressed:
                          \url{danfm@nyu.edu}}
\altaffiltext{\nyu}      {Center for Cosmology and Particle Physics,
                          Department of Physics, New York University,
                          4 Washington Place, New York, NY, 10003, USA}
\altaffiltext{\mpia}     {Max-Planck-Institut f\"ur Astronomie,
                          K\"onigstuhl 17, D-69117 Heidelberg, Germany}
\altaffiltext{\princeton}{Department of Astrophysics, Princeton University,
                          Princeton, NJ, 08540, USA} % CHECK THIS ZIP CODE
\altaffiltext{\berkeley} {Department of Astronomy,
                          University of California at Berkeley,
                          Berkeley, CA, XXXXX, USA} % CHECK THIS ZIP CODE

\begin{abstract}
Although no true extra-solar Earth analog is known, hundreds of planets have
been found around Sun-like stars that are either Earth-sized but on shorter
periods, or else on year-long orbits but somewhat bigger than Earth.
These populations ought to permit a (possibly highly uncertain) extrapolated
measurement of the probability or rate at which Sun-like stars host true Earth
analogs.
Here we build a set of probabilistic models of the population of known small
planets around G dwarfs.
The models take into account the transit probability and the completeness
(or detection efficiency) as a function of planet radius and orbital period.
Because we forward model the data, we do not ever have to perform any kind of
inverse-detection-efficiency weighting of the data.
Our most sophisticated models do not assume that the joint radius--period
distribution is separable.
They also correctly take into account the significant observational
uncertainties on the planet radii, using the machinery of hierarchical
inference.
We reconsider and confirm with weaker assumptions prior results on the
distribution of exoplanet radii that show a flattening of the distribution
below a few Earth radii.
One output of our models is fully marginalized estimates---marginalizing out
observational uncertainties and all distribution parameters---of the rate
density of true Earth analogs, expressed as a number of planets per star per
natural logarithmic interval of period and radius, evaluated at the properties
of Earth.
The rate density we infer is an extrapolation; it depends strongly on the
permitted flexibility of the distribution model, but it tends to come out
at around ten percent, with large uncertainty.
\end{abstract}

\keywords{%
exoplanets: sickness
---
exoplanets: eta-Earth
---
code: open-source
---
keywords: made-up-by-Hogg
}

\section{Introduction}

\hoggtodo{
\kepler\ has been busting out exoplanets (CITE).
Many of them even appear possibly rocky and habitable (CITE).
Nonetheless, none yet known are true Earth analogs.
}

\hoggtodo{
This hasn't stopped anyone from estimating the rate at which Sun-like stars
host Earth-like planets on year-ish period orbits (CITE).
All of these rate estimates are extrapolations of one kind or another.
Here we perform an extremely conservative extrapolation of this kind.
}

\hoggtodo{
What would make an extrapolation like this conservative?
Using \emph{huge bins} does not a conservative estimate make.
You don't want to assume separabilities you can't justify.
You want to explore an enormous function space for the exoplanet rates or pdf.
We are going to do be conservative in these senses here, far more conservative
than anyone who has come before.
}

This study is novel in a number of ways.
We create probabilistic information about the full exoplanet population
\emph{not} by weighting the detected objects by the inverse detection
efficiency (\citealt{petigura}), but rather by forward modeling the
observed distribution subject to the detection efficiency
(\dfmtodo{CITE TREMAINE?} \citealt{dong}).
Re-weighting the data by inverse selection probability---a method called
V-max in the quasar and galaxy luminosity function contexts---is not wrong,
but it produces a higher-variance estimate of the population than a justified
likelihood approach; it is higher variance because
the effective number of samples, after
weighting, can be much smaller than the actual number of samples.
In this work, we build a justified
likelihood of the observed data, taking into account the completeness function
or detection efficiency.
Our likelihood function is a variable-rate Poisson likelihood; it makes the
fundamental assumption that the data points are independently drawn from the
model, but is agnostic about all other properties of the data or distribution
functions.
Indeed, the assumptions behind this study here are weaker than those of any
previous study of the period and radius distribution of the Earth-sized
exoplanet population (\dfmtodo{CITE TREMAINE?} \citealt{dong, petigura}).

Another new aspect of this study is that it makes use of very flexible
distribution function models.
Indeed most of the models we consider are ``non-parametric'' in the weak sense
that they have enormous numbers of free parameters (not the strong sense of
having an \emph{infinite} number of free parameters).
The models are protected from degeneracies and over-fitting by priors.
In some models we assume that the two-dimensional distribution of planets in
period and radius is separable; in others we don't.
We treat all of these parameters as ``nuisance parameters'' when we ask
questions about the occurrence of Earth analogs.
That is, our rate conclusions are fully marginalized, and those
marginalizations are over non-trivial numbers of parameters.

When, in what follows, we ask questions about the radius disribution of
exoplanets, the distribution parameters are no longer nuisances The
radius-distribution parameters are what we are trying to measure.
Even in this case, however, our results will have the period-distribution
parameters marginalized out.

Perhaps the most important novelty of this study is in its treatment of
observational uncertainties.
Although planet periods in our data set are very precisely measured, the
planet radius measurements have large uncertainties.
The justified probabilistic approach to including these uncertainties in a
distribution analysis is to introduce the ``true'' radii as latent variables
and infer and marginalize them out along with all other nuisance parameters.
Although this sounds expensive---and it can be---there is a simple approach
we have been advocating (\cite{hogge}) that makes use of importance sampling.
We use this approach here; our results are fully marginalized over posterior
uncertainties in all of the planet radii.
More will be said about this below; the importance sampling looks like a
product over data points of sums (averages) over individual-datum radius
samplings.

\section{Model generalities}

\emph{Note: I think that we should use $T$ instead of $P$ for period because
$P$ is too heavily overloaded by the probabilities\ldots}

From our perspective, a ``model'' is a likelihood function---a probability
density (or distribution) function (PDF) for the data given
parameteters---and a set of prior PDFs for the parameters.
In what follows, we will treat as ``data'' a catalog of exoplanet period
and radius measurements (\citealt{petigura}).
\emph{(I don't think need this next sentence).}
We will treat the uncertainties on those measurements as ``prior
information''; that is, we will treat those as true as given and not as being
generated by the parameterized likelihood function.

In the models that follow, the most important parameters will be parameters
of the PDF for the exoplanet periods and radii.
However, there will also be ``latent parameters'' that represent the ``true''
values of the exoplanet periods \period\ and radii \radius.
That is, for each exoplanet, there is a ``measured'' or ``observed'' period
\obs{\period}\ and radius \obs{\radius}, which constitute our data.
These relate to the unobserved ``true'' period and radius by a noise model.
For the conclusions of this study, the true values of period and radius are
nuisance parameters; we will marginalize them out.

Let's also introduce more succinct notation for a \emph{catalog}.
We'll refer to the set of period and radius measurements for a set of $K$
candidate exoplanets as
\begin{eqnarray}
\catalog &=& \{\entry_k\}_{k=1}^K
\end{eqnarray}
where each entry $\entry_k = (\period_k,\,\radius_k)$ is a tuple containing a
period and radius.

The purpose of this \paper\ is to determine constraints on the \emph{rate
function} of exoplanets
\begin{eqnarray}\eqlabel{true-rate}
\rate_\ratepars (\entry)
&=& \frac{\dd N}{\dd\ln\period\dd\ln\radius}
\end{eqnarray}
given our dataset.
Here we have not made any assumptions about the functional form of \rate, we
are only stating that it can be modeled by some---possibly very large---set of
parameters \ratepars.

In this \paper, we will assume that the completeness function of the survey is
known and it can be represented as a probability at every (true) period and
radius $\completeness (\entry)$.
This probability will also include the geometric transit probability as a
function of period $\transitprob (\period)$.
These selection effects can be incorporated into the rate from \eq{true-rate}
to get the \emph{observable rate}
\begin{eqnarray}\eqlabel{obs-rate}
\obs{\rate}_\ratepars (\entry)
&=& \rate_\ratepars(\entry)\,\completeness(\entry)\quad.
\end{eqnarray}

Given this parameterized rate $\obs{\rate}_\ratepars$, we can compute the
Poisson likelihood of a \catalog\ (\citealt{tabachnik,youdin,dong})
\begin{eqnarray}\eqlabel{true-like}
\ln p(\catalog\,|\,\ratepars) &\propto&
\sum_{k=1}^K \ln\obs{\rate}_\ratepars (\entry_k)
- \int \obs{\rate}_\ratepars (\entry) \dd\entry
\end{eqnarray}
where we have assumed that every object in \catalog\ is an independent
Poisson sample from the rate.

If we had perfect noiseless measurements of the periods and radii for every
object in our catalog, \eq{true-like} provides a metric for determining
constraints on the parameters of the rate function.
In practice, the measurements of \catalog\ are noisy so we need to include
these effects.

\section{Including observational uncertainties}

The ``likelihood function'' given in \eq{true-like} is a model of the
probability of observing a catalog with \emph{true} periods and radii.
If we want to include the effects of measurement uncertainties, we need to
take a moment to consider the meaning of measurement uncertainties.

\dfmtodo{Introduce the idea of catalogs with uncertainties being a description
of a posterior sampling over catalogs: $\catalog^{(n)} \sim
p(\catalog\,|\,\obs{\catalog},\,\interim)$.}

The quantity that we need to compute is the \emph{marginalized likelihood} of
the data \obs{\catalog}\ given a particular setting of the rate function
parameters \ratepars.
This is achieved by marginalizing over the true periods and radii
\begin{eqnarray}
p(\obs{\catalog}\,|\,\ratepars) &=&
\int p(\catalog,\,\obs{\catalog}\,|\,\ratepars) \dd\catalog \\
&=&
\int p(\catalog\,|\,\ratepars)\,p(\obs{\catalog}\,|\,\catalog) \dd\catalog
\end{eqnarray}
where the second line is true because the rate function is defined on the true
parameters.
This integral can then be written in terms of the sampling under interim
priors
\begin{eqnarray}
p(\obs{\catalog}\,|\,\ratepars)
&=&
\int p(\catalog\,|\,\ratepars)\,p(\obs{\catalog}\,|\,\catalog)\,
\frac{p(\catalog\,|\,\obs{\catalog},\,\interim)}
     {p(\catalog\,|\,\obs{\catalog},\,\interim)}
\dd\catalog
\\
&=&
p(\obs{\catalog}\,|\,\interim)\,
\int \frac{p(\catalog\,|\,\ratepars)}{p(\catalog\,|\,\interim)}\,
p(\catalog\,|\,\obs{\catalog},\,\interim)
\dd\catalog \quad.
\end{eqnarray}
We can approximate this integral using the samples $\catalog^{(n)}$ defined
above and find the marginalized likelihood up to an unimportant normalization
constant
\begin{eqnarray}\eqlabel{marg-like}
p(\obs{\catalog}\,|\,\ratepars) &\appropto&
\sum_{n=1}^N
\frac{p(\catalog^{(n)}\,|\,\ratepars)}{p(\catalog^{(n)}\,|\,\interim)}
\end{eqnarray}
where the numerator inside the sum is given by \eq{true-like} and the
denominator is the interim prior evaluated at the samples.

In practice, the variance of this approximation depends on the choice of
interim prior and, in particular, it is useful to include the completeness
function.
\dfmtodo{BLAH BLAH BLAH.}

\section{The completeness function \& dataset}

\dfmtodo{%
Describe Erik's data products and our model of the completeness in boxes
extended artificially beyond the original range.
Also describe the re-sampling procedure for the candidate parameters.
}

\section{Separable distribution}

The first model that we consider for $\rate(\period,\,\radius)$ is a simple
separable distribution.
This assumption means that the rate can be written as
\begin{eqnarray}
\rate(\period,\,\radius) &=& \rate(\period)\,\rate(\radius)
\end{eqnarray}
and, more specifically, we model the period distribution as a broken power law
\dfmtodo{CHECK ME!!}
\begin{eqnarray}
\rate(\period) &\propto& \frac{\period^\alpha \,
(\period+\period_0)^{\beta-\alpha}}{\period_0^\beta}
\end{eqnarray}
and the radius distribution as a piecewise constant function (or histogram)
where the parameters are the bin heights.

\section{Discussion}

We have made the first measurement of the Earth-like exoplanet population that
is based on forward modeling, takes proper account of the observational
uncertainties on planet radii, and makes use of extremely flexible
non-separable distributions for period and radius.
We find \hoggtodo{BLAH BLAH BLAH.}

Although our method makes weaker assumptions than any previous work in this
area, of course it \emph{does} make strong assumptions.
It assumes that the data set (from \citealt{petigura}) contains planets and
only planets (no false positives).
It assumes that the individual-planet radius uncertainties are also correctly
determined.
It assumes that the completeness calculation (again from \citealt{petigura})
is accurate and smoothly varying with period and radius; it makes no attempt
to adjust the completeness star-by-star for brightness or variability.
It assumes that the exoplanets are all independently drawn from the same
distribution function, with no regard to age, metallicity, or multiplicity.

Although we have taken account of the radius uncertainties in a principled
way, we did make one important approximation: We ignored planets with central
values far outside the period and radius box in which we built the model.
That is, we assumed that there are no very large outliers in radius
determination.
This assumption is a complex one; it involves the effective, end-to-end error
distribution in the data set, but also smoothness of the distribution function
at or near the edges of the analysis box.

If our inferences are right about true Earth analogs, then we expect that
there are about XXX transiting Earth analogs hidden in the \kepler\ data set.
We would be able to find some of these Earth analogs if the effective noise
level in the data could be reduced by a factor of about XXX.
We have identified a number of directions along which this noise reduction
might happen, including but not limited to retrospective data-driven or
physics-driven recalibrations of the \kepler\ focal plane
(\citealt{hoggwhitepaper}), new methods for performing aperture photometry,
and better models for stochastic instrument variability or stochastic
intrinsic stellar variability that take account of frequency structure
(\citealt{brewer, carter, roberts}).
If any (or all) of these deliver substantial improvements for \kepler\
archival data reanalyses, it's Nobel Prize time!  (Or at least \textsl{The
Colbert Report}?)

\acknowledgments
It is a pleasure to thank
    \ldots
for helpful contributions to the ideas and code presented here.
This project was partially supported by the NSF (grant AST-0908357), and NASA
(grant NNX08AJ48G).
This research made use of the NASA \project{Astrophysics Data System}.

\newcommand{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{arXiv:#1}}
\begin{thebibliography}{}\raggedright

\bibitem[Brewer \& Stello(2009)]{brewer}
Brewer, B.~J., \& Stello, D.\ 2009, \mnras, 395, 2226 (\arxiv{0902.3907})

\bibitem[Carter \& Winn(2009)]{carter}
Carter, J.~A., \& Winn, J.~N.\ 2009, \apj, 704, 51 (\arxiv{0909.0747})

\bibitem[Dong \& Zhu(2013)]{dong}
Dong, S., \& Zhu, Z.\ 2013, \apj, 778, 53 (\arxiv{1212.4853})

\bibitem[Hogg \etal(2013)]{hoggwhitepaper}
Hogg, D.~W., Angus, R., Barclay, T., et al.\ 2013, \arxiv{1309.0653}

\bibitem[Hogg \etal(2010)]{hogge}
Hogg, D.~W., Myers, A.~D., \& Bovy, J.\ 2010, \apj, 725, 2166 (\arxiv{1008.4146})

\bibitem[Petigura \etal(2013)]{petigura}
Petigura, E.~A., Howard, A.~W., \& Marcy, G.~W.\ 2013,
Proceedings of the National Academy of Science, 110, 19273 (\arxiv{1311.6806})

\bibitem[Roberts \etal(2013)]{roberts}
Roberts, S., McQuillan, A., Reece, S., \& Aigrain, S.\ 2013, \mnras, 435, 3639
(\arxiv{1308.3644})

\bibitem[Tabachnik \& Tremaine(2002)]{tabachnik}
Tabachnik, S., \& Tremaine, S.\ 2002, \mnras, 335, 151
(\arxiv{astro-ph/0107482})

\bibitem[Youdin(2011)]{youdin}
Youdin, A.~N.\ 2011, \apj, 742, 38 (\arxiv{1105.1782})

\end{thebibliography}

\end{document}
